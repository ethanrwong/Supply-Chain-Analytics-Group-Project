---
title: "ARIMA Ingredients Model"
author: "Ethan Wong"
date: "2024-11-24"
output: html_document
---

### Reading in Libraries and Data

```{r message=FALSE, warning=FALSE}
# Load Libraries
library(fable)
library(fpp3)
library(tseries)
library(tsibble)
library(forecast)
library(ggplot2)
library(dplyr)
library(lubridate)
library(tibble)
library(patchwork)

# Load Data
data <- read.csv("data_formatted.csv")

# Convert Data into a tsibble
data_tsibble <- data %>%
  mutate(Date = as.Date(Date, format = "%Y-%m-%d")) %>%
  as_tsibble(index = Date, key = Ingredient)
```

### Checking for Stationarity

```{r message=FALSE, warning=FALSE}
# Add first and second differences
data_diff <- data_tsibble %>%
  mutate(diff_1 = difference(Sales_Units),
         diff_2 = difference(diff_1))

# Plot the time series for each ingredient
data_tsibble %>%
  autoplot(Sales_Units) +
  ggtitle("Time Series of Sales for Each Ingredient") +
  xlab("Date") +
  ylab("Sales Units") +
  facet_wrap(~ Ingredient, scales = "free_y")

# Plot first and second differences
data_diff %>%
  autoplot(diff_1) +
  ggtitle("First Difference of Sales Units") +
  xlab("Date") +
  ylab("First Difference") +
  facet_wrap(~ Ingredient, scales = "free_y")

data_diff %>%
  autoplot(diff_2) +
  ggtitle("Second Difference of Sales Units") +
  xlab("Date") +
  ylab("Second Difference") +
  facet_wrap(~ Ingredient, scales = "free_y")
```

Based on these three plots, it seems unlikely that differencing is needed to achieve stationarity. However, we can confirm this with a KPSS test.

```{r}
# Perform KPSS test on the original series, first, and second differences
data_tsibble %>%
  features(Sales_Units, unitroot_kpss)

data_diff %>%
  features(diff_1, unitroot_kpss)

data_diff %>%
  features(diff_2, unitroot_kpss)
```

For the KPSS test, the null hypothesis is that the series is stationary. Since we have p-values > 0.05 for shrimp and steak on the original series, we cannot reject stationarity. However, for tomato, there is a possibility of non-stationarity. We can also check with an ADF test. 

```{r message=FALSE, warning=FALSE}
# Perform ADF test for each ingredient on original series, first difference, and second difference
adf_results <- data_diff %>%
  group_by(Ingredient) %>%
  group_modify(~ {
    # ADF test on original series
    adf_original <- adf.test(.x$Sales_Units, alternative = "stationary")
    
    # ADF test on first difference
    adf_diff_1 <- adf.test(na.omit(.x$diff_1), alternative = "stationary")
    
    # ADF test on second difference
    adf_diff_2 <- adf.test(na.omit(.x$diff_2), alternative = "stationary")
    
    # Return results as a tibble
    tibble(
      adf_p_value_original = adf_original$p.value,
      adf_p_value_diff_1 = adf_diff_1$p.value,
      adf_p_value_diff_2 = adf_diff_2$p.value
    )
  })

print(adf_results)
```

For the ADF test, the null hypothesis is that the series is not stationary. Since the p-values are < 0.05, we can reject the null hypothesis, even at the original series level. It is safe to say that differencing is likely not needed for steak and shrimp and that the original series for those is stationary. However, since the KPSS and ADF results disagree for tomato, the auto.arima() function may use d = 1 for that series.

### Determining Order of Appropriate ARIMA Models

Here, we examine the ACF and PACF in order to determine what order of ARIMA models may be appropriate.

```{r}
# Plot ACF and PACF for each ingredient
data_tsibble %>%
  filter(Ingredient == "Shrimp") %>%
  gg_tsdisplay(Sales_Units, plot_type = "partial") +
  ggtitle("ACF and PACF for Shrimp Sales Units")

data_tsibble %>%
  filter(Ingredient == "Steak") %>%
  gg_tsdisplay(Sales_Units, plot_type = "partial") +
  ggtitle("ACF and PACF for Steak Sales Units")

data_tsibble %>%
  filter(Ingredient == "Tomato") %>%
  gg_tsdisplay(Sales_Units, plot_type = "partial") +
  ggtitle("ACF and PACF for Tomato Sales Units")

```

Based on these three sets of plots, it seems that all three ingredients show strong weekly seasonality in their sales data, indicated by the periodic spikes at multiples of 7 in the ACF plots. Significant spikes at lag 1 in the PACF plots across all three ingredients indicate that an AR(1) component should be included in the models. We hypothesize the following model fits for each ingredient:

* Shrimp: SARIMA(p=1, d=0, q=0)(P=1, D=0, Q=0)[7]
* Steak: SARIMA(p=1, d=0, q=0)(P=1, D=0, Q=0)[7]
* Tomato: SARIMA(p=1, d=1, q=0)(P=1, D=1, Q=0)[7]

### Fitting SARIMA Models

Due to the inherent seasonality that appears to be weekly, we will now use auto.arima() to fit models for Shrimp, Steak and Tomato. We will also manually fit our hypothesized ARIMA configurations for these three ingredients for comparison.  

```{r}
# Fit auto.arima for each ingredient
ingredients <- unique(data_tsibble$Ingredient)

models <- list()

for (ingredient in ingredients) {
  # Filter the data for the specific ingredient
  ingredient_data <- data_tsibble %>%
    filter(Ingredient == ingredient) %>%
    as_tsibble(index = Date)
  
  # Convert to time series object for auto.arima
  ts_data <- ts(ingredient_data$Sales_Units, frequency = 7) # Weekly seasonality
  
  # Fit seasonal ARIMA model
  model <- auto.arima(ts_data, seasonal = TRUE, stepwise = FALSE, approximation = FALSE)
  
  # Store the model in a list
  models[[ingredient]] <- model
  
  # Print model summary
  cat(paste("Seasonal ARIMA model for", ingredient, ":\n"))
  print(model)
  cat("\n")
}
```

```{r}
# Fit SARIMA model for Shrimp
model_shrimp <- data_tsibble %>%
  filter(Ingredient == "Shrimp") %>%
  model(SARIMA = ARIMA(Sales_Units ~ 0 + pdq(1,0,0) + PDQ(1,0,0)))

# Fit SARIMA model for Steak
model_steak <- data_tsibble %>%
  filter(Ingredient == "Steak") %>%
  model(SARIMA = ARIMA(Sales_Units ~ 0 + pdq(1,0,0) + PDQ(1,0,0)))

# Fit SARIMA model for Tomato
model_tomato <- data_tsibble %>%
  filter(Ingredient == "Tomato") %>%
  model(SARIMA = ARIMA(Sales_Units ~ 0 + pdq(1,1,0) + PDQ(1,1,0)))

model_shrimp %>% report()
model_steak %>% report()
model_tomato %>% report()
```
When comparing the auto.arima() to the manually fitted ARIMA models, the auto fitted models perform better in terms of AIC, AICc, and BIC along with residual variance (sigma^2). The models selected by auto.arima() are:

* Shrimp: SARIMA(3,0,0)(2,1,0)[7]
* Steak: SARIMA(0,0,0)(2,1,0)[7]
* Tomato: SARIMA(0,0,0)(0,1,1)[7]

While these are more complex and harder to interpret as far as coefficients go, they are a better fit and have better explanatory power. 

### Residual and Information Criteria Analysis

Next, we will perform a residual analysis to validate assumptions of independence. To start, we will perform a ljungbox test.

```{r}
# Refit models with optimal parameters identified with auto.arima()
model_shrimp <- data_tsibble %>%
  filter(Ingredient == "Shrimp") %>%
  model(SARIMA = ARIMA(Sales_Units ~ 0 + pdq(3,0,0) + PDQ(2,1,0)))
model_steak <- data_tsibble %>%
  filter(Ingredient == "Steak") %>%
  model(SARIMA = ARIMA(Sales_Units ~ 0 + pdq(0,0,0) + PDQ(2,1,0)))
model_tomato <- data_tsibble %>%
  filter(Ingredient == "Tomato") %>%
  model(SARIMA = ARIMA(Sales_Units ~ 0 + pdq(0,0,0) + PDQ(0,1,1)))

# Perform a ljungbox test for each model
model_shrimp %>% augment() %>%
  features(.resid, ljung_box, lag = 10)
model_steak %>% augment() %>%
  features(.resid, ljung_box, lag = 10)
model_tomato %>% augment() %>%
  features(.resid, ljung_box, lag = 10)
```
The null hypothesis is that residuals are uncorrelated. Since all three models have a p-value > 0.05, so we conclude that the residual independence cannot be rejected.

Next, we look at the plots of the residuals for each model.
```{r}
model_shrimp %>% gg_tsresiduals()
model_steak %>% gg_tsresiduals()
model_tomato %>% gg_tsresiduals()
```
Based on these residual outputs, we see small spikes in ACF at seasonal lags (7, 14, etc.) suggest that the weekly seasonality might not be fully captured in the models for shrimp and steak. All three models to show extreme residuals, which could be due to a systematic effect the models are not capturing. However, these residuals are all approximately symmetric (though heavy tails exist for shrimp and steak).

Next, we examine the information criteria for the models under consideration.

```{r}
glance(model_shrimp)
glance(model_steak)
glance(model_tomato)
```
Based on these results, it seems that the Shrimp model has the lowest AIC and BIC among the candidate models, with tomato having significantly higher AIC/BIC due to higher variance (sigma^2). 

### Cross-Validation of Candidate Models:

To cross-validate a time-series forecasting model, we need to extend the file to repeatedly fit the model. We start by assuming that the initial data consists of 70% of the data in the code below. Then in a sequential fashion, we recalculate the model assuming seven additional points (datums) are observed. Finally we can calculate the out-of-sample accuracy metrics by comparing each forecast in the horizon with the available data.

```{r warning=FALSE}
# Initialize an empty tibble to store accuracy metrics
all_accuracy_metrics <- tibble()

# Define a function to calculate accuracy for a given ingredient
calculate_accuracy <- function(data, ingredient, auto_formula, manual_formula) {
  # Filter the data for the specific ingredient
  ingredient_data <- data %>%
    filter(Ingredient == !!ingredient)
  
  # Stretch tsibble for cross-validation
  cv_data <- ingredient_data %>%
    stretch_tsibble(.init = 426, .step = 7)
  
  # Fit the models
  cv_models <- cv_data %>%
    model(
      AutoSARIMA = ARIMA(auto_formula),
      ManualSARIMA = ARIMA(manual_formula)
    )
  
  # Forecast and compute accuracy
  cv_forecasts <- cv_models %>%
    forecast(h = 14)
  
  # Compute accuracy and add the ingredient as a column
  cv_forecasts %>%
    accuracy(ingredient_data) %>%
    mutate(Ingredient = !!ingredient) %>%
    return()
}

# Add results for Shrimp
all_accuracy_metrics <- bind_rows(
  all_accuracy_metrics,
  calculate_accuracy(
    data_tsibble, "Shrimp",
    auto_formula = Sales_Units ~ pdq(3, 0, 0) + PDQ(2, 1, 0),
    manual_formula = Sales_Units ~ pdq(1, 0, 0) + PDQ(1, 0, 0)
  )
)

# Add results for Steak
all_accuracy_metrics <- bind_rows(
  all_accuracy_metrics,
  calculate_accuracy(
    data_tsibble, "Steak",
    auto_formula = Sales_Units ~ pdq(0, 0, 0) + PDQ(2, 1, 0),
    manual_formula = Sales_Units ~ pdq(1, 0, 0) + PDQ(1, 0, 0)
  )
)

# Add results for Tomato
all_accuracy_metrics <- bind_rows(
  all_accuracy_metrics,
  calculate_accuracy(
    data_tsibble, "Tomato",
    auto_formula = Sales_Units ~ pdq(0, 0, 0) + PDQ(0, 1, 1),
    manual_formula = Sales_Units ~ pdq(1, 1, 0) + PDQ(1, 1, 0)
  )
)

print(all_accuracy_metrics)
```

As expected, the models selected by Auto ARIMA have lower RMSE and MAE across all ingredients, confirming better predictive accuracy. MPE/MAPE is Inf/NAN for several models due to the 0 values on Sundays. ACF1 values (autocorrelation of residuals at lag 1) are close to zero for all models in Shrimp and Steak, indicating minimal autocorrelation in residuals. Interestingly, tomato shows higher ACF1 for the Manual ARIMA model we hypothesized (0.409), suggesting significant residual autocorrelation and potential model misspecification.

Below, we do a comparison of RMSE for each model and ingredient. 

```{r}
# Plot RMSE for each ingredient and model
ggplot(all_accuracy_metrics, aes(x = Ingredient, y = RMSE, fill = .model)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "RMSE Comparison of AutoSARIMA and ManualSARIMA Models",
    x = "Ingredient",
    y = "RMSE",
    fill = "Model"
  ) +
  theme_minimal()
```
From the above graph, we see that the Auto ARIMA models perform slightly better than the manual, hypothesized ARIMA models for steak and shrimp. However, this improvement is much more dramatic for the Tomato Auto ARIMA model compared to the Tomato Manual ARIMA model. Tomato sales in general were more volatile, so this is to be expected.

Lastly, we look at the forecast plots of the Auto ARIMA and Manual ARIMA plots below.

```{r warning=FALSE}
# Generate forecasts for Shrimp
shrimp_forecast <- data_tsibble %>%
  filter(Ingredient == "Shrimp") %>%
  model(
    AutoSARIMA = ARIMA(Sales_Units ~ pdq(3,0,0) + PDQ(2,1,0)),
    ManualSARIMA = ARIMA(Sales_Units ~ pdq(1,0,0) + PDQ(1,0,0))
  ) %>%
  forecast(h = 14)

# Generate forecasts for Steak
steak_forecast <- data_tsibble %>%
  filter(Ingredient == "Steak") %>%
  model(
    AutoSARIMA = ARIMA(Sales_Units ~ pdq(0,0,0) + PDQ(2,1,0)),
    ManualSARIMA = ARIMA(Sales_Units ~ pdq(1,0,0) + PDQ(1,0,0))
  ) %>%
  forecast(h = 14)

# Generate forecasts for Tomato
tomato_forecast <- data_tsibble %>%
  filter(Ingredient == "Tomato") %>%
  model(
    AutoSARIMA = ARIMA(Sales_Units ~ pdq(0,0,0) + PDQ(0,1,1)),
    ManualSARIMA = ARIMA(Sales_Units ~ pdq(1,1,0) + PDQ(1,1,0))
  ) %>%
  forecast(h = 14)

# Shrimp forecast plot
shrimp_plot <- autoplot(shrimp_forecast, data = data_tsibble %>% filter(Ingredient == "Shrimp")) +
  labs(title = "Forecast for Shrimp Sales Units", x = "Date", y = "Sales Units") +
  theme_minimal() +
  xlim(as.Date("2024-08-15"), as.Date("2024-09-15")) # Adjust to forecast range

# Steak forecast plot
steak_plot <- autoplot(steak_forecast, data = data_tsibble %>% filter(Ingredient == "Steak")) +
  labs(title = "Forecast for Steak Sales Units", x = "Date", y = "Sales Units") +
  theme_minimal() +
  xlim(as.Date("2024-08-15"), as.Date("2024-09-15"))

# Tomato forecast plot
tomato_plot <- autoplot(tomato_forecast, data = data_tsibble %>% filter(Ingredient == "Tomato")) +
  labs(title = "Forecast for Tomato Sales Units", x = "Date", y = "Sales Units") +
  theme_minimal() +
  xlim(as.Date("2024-08-15"), as.Date("2024-09-15"))

shrimp_plot <- shrimp_plot +
  theme(legend.position = "bottom") # Moves legend below the plot

steak_plot <- steak_plot +
  theme(legend.position = "bottom") # Moves legend below the plot

tomato_plot <- tomato_plot +
  theme(legend.position = "bottom") # Moves legend below the plot
```

```{r warning=FALSE}
shrimp_plot
steak_plot
tomato_plot
```


For shrimp, the Auto ARIMA shows tighter confidence intervals, indicating higher certainty compared to the Manual ARIMA model. The same can be said for the steak model, as the Auto ARIMA model has smoother predictions. Lastly, despite the uncertainty in tomato sales, the Auto ARIMA model still shows tighter confidence intervals, indicating a better model fit. 

Overall, tomato sales are the most challenging to model, likely due to higher variability or unique seasonal patterns. However, the ARIMA model performs very well for modeling and forecasting the sales of these ingredients, and the performance could be further evaluated with comparable data for the forecast period along with more historical data. We also considered aggregating the data for each week for each ingredient and fitting ARIMA models this way. However, the results were determined to be white noise by ARIMA and thus, unsuitable for any sort of forecasting usage.  
